{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import multiprocessing\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lib.helpers as hlp\n",
    "import lib.backtest as backtest\n",
    "import lib.plotting as plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all backtest settings\n",
    "historical_df = hlp.get_historical_prices_df()\n",
    "input_df = pd.read_csv(os.path.join(hlp.INPUT_DATA_DIR, \"instruments_mc_125.csv\"), sep=',')\n",
    "premium_offset = 0. # 1 stands for 100% increase from the original premium values\n",
    "simulation_length_days = 1000 # number of days\n",
    "number_of_paths = 500 # number of the random paths to do backtest\n",
    "number_of_utils = 100 # number of utils on the [0, 1] segment, passed to the get_kelly_curve\n",
    "number_of_bins = np.linspace(-1, 5, 1000) # Number of bins. Could be also string (e.g. 'auto') or list of bin edges. Whatever complies with np.histogram\n",
    "initial_util = 0.2\n",
    "monte_carlo_paths = 1000\n",
    "bonding_curve_resolution = 100\n",
    "multiproc_cores = os.cpu_count() // 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b942b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_info_dicts = input_df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiproc_args_kelly_list = []\n",
    "\n",
    "for asset_dict in assets_info_dicts:\n",
    "    multiproc_args_kelly = [\n",
    "        asset_dict.copy(),\n",
    "        simulation_length_days,\n",
    "        historical_df,\n",
    "        monte_carlo_paths,\n",
    "        bonding_curve_resolution,\n",
    "        number_of_paths,\n",
    "        0,\n",
    "        \"kelly\",\n",
    "        0,\n",
    "    ]\n",
    "    multiproc_args_kelly_list.append(multiproc_args_kelly)\n",
    "# backtest each instrument from the assets_info_dicts\n",
    "# and add the result to the res_assets_info_dicts\n",
    "pool = multiprocessing.Pool(multiproc_cores)     \n",
    "res_assets_info_dicts = pool.starmap(backtest.backtest_asset_dict, multiproc_args_kelly_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack all the info the the DataFrame\n",
    "summary_df = pd.DataFrame(res_assets_info_dicts)\n",
    "# summary_df.sort_values(by='median_bankroll').head()\n",
    "\n",
    "# unpack percentiles\n",
    "percentile_df = pd.DataFrame(summary_df.max_drawdown_percentiles.tolist(), index= summary_df.index)\n",
    "percentile_df.rename(columns=lambda col: f'{(0, 25, 50, 75, 100)[col]}_percentile_max_drawdown', inplace=True)\n",
    "cagr_percentile_df = pd.DataFrame(summary_df.cagr_percentiles.tolist(), index= summary_df.index)\n",
    "cagr_percentile_df.rename(columns=lambda col: f'{(0, 25, 50, 75, 100)[col]}_percentile_cagr', inplace=True)\n",
    "summary_df = summary_df.merge(percentile_df, left_index=True, right_index=True)\n",
    "summary_df = summary_df.merge(cagr_percentile_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results if needed\n",
    "summary_df.drop(columns=['price_series', 'premium_vs_util_df', 'bankroll_df']).to_csv(os.path.join(hlp.OUTPUT_DATA_DIR, 'flow2_results_new.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.flow2_plot(\n",
    "        summary_df,\n",
    "        hue=\"option_type\",\n",
    "        cagr_pick=None,\n",
    "        max_drawdown_pick=None,\n",
    "        x_axis=\"100_percentile_max_drawdown\",\n",
    "        y_axis=\"50_percentile_cagr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973e375",
   "metadata": {},
   "source": [
    "# Create instuments batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assets = [asset for asset in historical_df.columns if (not 'Unnam' in asset and not 'Master' in asset)]\n",
    "strike_pcts = [i for i in range(-10, 10, 10)]\n",
    "durations = [i for i in range(1, 31, 10)]\n",
    "utilizations = [0.5]\n",
    "train_start_dates = ['min']\n",
    "train_end_dates = ['max']\n",
    "moods = ['Full History'] # , 'bear', 'bull'\n",
    "\n",
    "columns = ['asset', 'strike_pct', 'duration', 'util', 'train_start_date', 'train_end_date', 'mood']\n",
    "\n",
    "all_combinations = list(itertools.product(assets, strike_pcts, durations, utilizations, train_start_dates, train_end_dates, moods))\n",
    "instruments_df = pd.DataFrame(all_combinations, columns=columns)\n",
    "instruments_df.to_csv(os.path.join(hlp.INPUT_DATA_DIR, 'flow2_input.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instruments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0150e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e9759e959cdcc1b78706c9778e3922ea04b0559b25c8a5a0960ecccb9cdbb82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
